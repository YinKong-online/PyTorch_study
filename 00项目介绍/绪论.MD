### 写在前面

1956年，一群科学家齐聚在达特茅斯开了一场会议，只有十来个人参加，也只持续了一个月，看似一场很小的会议，却深刻地改变了未来几十年世界的样貌。这场会议的中心议题是：如何制造一种可以不断学习并且模拟人类智能的机器，而它的产物便是——**人工智能（Artificial Intelligence, AI）**。

**人工智能（AI）**，顾名思义是人工搭建起来的智能。“人工”很好理解，但“智能”又是什么呢？

智能本质上是针对不同情景做出针对性处理的能力。而人工智能，则是让人类搭建起一套可以根据不同输入内容给出针对性输出内容的系统，输出可以是动作、语言，也可以是一种判断。

这就需要我们找到这样一个“黑箱”，一个建立输入与输出对应关系的“函数”。正如图灵测试所定义的：若一个人无法辨别聊天对象是人还是机器，那么这台机器即可被认为具有智能。函数的特性是确定的，给定输入便有固定输出，无论操作者是谁，相同输入总能得到相同结果。

现在的问题是如何做出这样的“黑箱”。科学家们给出了很多思路。比如，一些人从数学的严谨形式化推理体系（离散数学）中获得灵感，认为智能可以通过符号的逻辑推理来模拟，这便是**符号主义（Symbolism）**。举个例子：若A代表“阴天”，B代表“湿度大于70%”，C代表“会下雨”，那么当A和B都为真时，C就为真（即A∧B→C）。人类的许多思考过程，本质上就是这样的逻辑推理。因此，符号主义者相信智能正是一套处理规则和符号的计算系统。这个系统将人类已有的知识和逻辑储存下来，通过不断的逻辑推演，就能实现接近人类的智能。

符号主义最成功的应用是**专家系统（Expert System）**。它学习人类专家的各种知识和规则，根据这些规则对输入信息进行推理，从而给出预测或决策，曾在金融分析、疾病诊断等领域大放异彩。

但随着时间推移，符号主义的缺陷逐渐暴露：现实世界中并没有那么多清晰的规则；同一个问题，不同专家可能给出不同甚至相反的答案；更关键的是，专家系统的能力上限取决于人类专家，无法超越人类，且一旦设定，水平就固定不变，无法像人类一样通过经验积累提升。

正因如此，从20世纪70年代开始，另一个人工智能流派逐渐兴起——**机器学习（Machine Learning）**。这一流派不追求AI一开始就有多高的水平，而是允许它通过学习不断进步。

人们只需要一个具备学习能力的“黑箱”和足够的训练数据，通过“奖励正确、惩罚错误”的机制（类似巴甫洛夫的条件反射实验），就能让这个“黑箱”变得越来越智能。

理解这个原理后，剩下三个核心问题：如何设计“黑箱”（模型结构）、如何定义奖惩（损失函数）、如何高效学习（训练过程）。这三个问题分别对应了现代人工智能的基础框架。

先来思考第一个问题：如何设计具备学习能力的“黑箱”。这时不得不提到另一个人工智能流派——**联结主义（Connectionism）**。联结主义者认为，大自然进化已经给出了实现智能的标准答案——人类的大脑。只需通过仿生方式模拟神经元的功能及其相互联系，就能构建出具有智慧的人工智能系统。

为理解这个思想，我们可以举一个简单的例子：当你看到一个苹果时，你知道它是苹果，是因为它具备红色、直径约10厘米、球形、有香气等特征。你对苹果的认知，正是由这些不同维度的特征值叠加而成的。我们区分不同物体，正是依靠这些维度特征值的差异。

如果我们记住这些特征值，那么遇到新水果时，只需将其特征值与已知水果的特征值进行比较，若与苹果的特征值相近，就可以认为它是苹果。这便是一种简单的智能。

这给了我们启示：可以搭建这样一个“黑箱”，将所有维度（如颜色、大小等）的值作为输入，为每个维度分配不同的权重（系数），将这些加权后的特征值相加得到一个总分，再设置一个阈值。若总分高于阈值，就“激活”输出。用公式表示即：```w₁x₁ + w₂x₂ + w₃x₃ + … - b > 0```。而像“红色”这个的东西，需用**激活函数**转为合适的数据。

这种模式识别算法模型，便是1957年提出的**感知机（Perceptron）**。

细心的你会发现，感知机的结构与神经元非常相似——通过接收多个信号，决定是否激活神经元的活动。事实上，这种模型的提出更早，早在1943年就有科学家发表过相关论文。

当世界上第一台感知机问世后，人们曾过于乐观，认为只要增加神经元数量就能创造出强大的人工智能。然而，正如1900年的物理学，这个过于简单的模型根本无法承载如此重任。

1969年，马文·明斯基在《感知机》一书中指出了感知机的致命缺陷：它只能解决线性可分问题，连简单的**异或运算（XOR Operation）**（输入相同为0，不同为1）都无法完成。

这是因为感知机的数学模型本质是线性分类器，只能用直线划分数据。而异或问题是非线性可分的，感知机根本无法做到。

这一发现使联结主义陷入低谷，此后二三十年里，感知机几乎成了“伪科学”的代名词。但仍有一些科学家坚持探索，为后来的**深度学习**奠定了基础。

这些科学家思考：既然单个神经元无法处理异或问题，何不增加神经元的数量和层次？于是，他们设计出**多层感知机（Multi-Layer Perceptron, MLP）**——让第一层感知机的输出作为第二层的输入，层层传递，最终得到结果。

多层感知机的层数远不止两层，每层的输入输出也不止两个。这些神经元层层叠加，便组成了**神经网络（Neural Network）**。

现代科学已经证明，只要**神经网络**的深度和宽度足够大，理论上可以模拟任何函数。

回过头看，人类的大脑也是由大量神经元连接而成的。正如我们最初的目标——模拟人类智能，人工智能的形态自然也应是对人类大脑的模拟。

进一步研究发现，人类大脑中并非所有神经元都相互连接，有些不必要的连接可以省略。这一发现催生了后来各种各样的神经网络模型，如**卷积神经网络 Convolutional Neural Network**、**残差网络 Residual Network**等。由于输入数据的特性不同，识别过程中不需要所有神经元全连接，而是可以根据数据特性进行选择性连接。如何设计这些连接方式，成为深度学习的重要研究领域——神经网络结构设计。

再来看第二个问题：如何定义奖惩。训练巴甫洛夫的狗时，我们可以用骨头奖励，或用没有骨头惩罚。那么**神经网络**的奖惩机制是什么？其实，奖惩的目的是让网络学习到正确的参数。如何找到这些参数的最优值，便是数学中的**梯度下降**方法（详见本章节《数学基础.MD》）。

第三个问题：机器如何建立输入与输出的对应关系。这是一个相当“玄学”的问题。训练机器就像学生做练习题——通过大量练习，就能举一反三解决类似问题。当问学生为什么这样解题时，他可能会说“我做过类似的题，感觉应该用这个公式”。机器建立的对应关系同样难以解释，甚至我们人类自己也不清楚自己是如何建立某些认知关系的（至少在本章写作时，这一问题尚未完全解决）。

这种对应关系的建立非常抽象。例如，现在很多人会把“篮球”和“鸡”联系到一起（网络迷因）。**神经网络**能领悟到什么样的对应关系，完全取决于训练数据。它可能会从数据中学习到一些看似无关的关联。

有人因此认为**神经网络**存在缺陷。但在我看来，这种“奇怪”关联的建立，恰如心理学中的“幸存者偏差”——人类会因为见到更多的“幸存者”而对事物产生错误判断。**神经网络**产生奇怪关联的部分原因，也可能是因为它所接触的数据本身就包含“幸存者偏差”，导致它产生了类似的认知偏差（当然，还有部分原因可能源于模型本身的特性，就像人与人之间的差异——有些人能理解抽象的梗，有些人则不能）。

以上便是**人工智能**的发展历程。在本项目的后续章节中，我们将详细讲解各种**神经网络**模型。

在我们进入**神经网络**模型的讲解之前，让我们把目光回到**多层感知机**。我们设计它的时候，有了**感知机**，而它的形式是线性加权求和，为了非线性的激活，我们把多层链接，形成**多层感知机**，形成**全连接神经网络（Fully Connected, FC）**。每一层的**FC**对每个输出节点都考虑了全部的输入数据，这导致它效率不高。对于每一个输出点，它所用到的输入数据不一定的全部。我们可能只需要用到其中一部分数据，而其他数据对结果没有影响。

如何只用到一部分数据，那我们可以想想，**感知机**是怎么处理的，对输入的数据```[x1, x2, x3, x4, ...]```(命名为X列表),我们有```[w1, w2, w3, w4, ...]```(命名为W列表),
通过调整```w1, w2, w3, w4, ...，b```（b是阈值）,我们可以得到效果不同的**感知机**。

那么为了只用到部分数据，我们可以让**W列表**短一点（这就是**卷积核**），让它**滑动重复**使用，这样每次运算的的时候就用一部分数据，当然计算方法照旧，```w₁x₁ + w₂x₂ + w₃x₃ + ... + wₙxₙ(n = len(W))```。

恭喜你，你创造了**卷积神经网络（Convolutional Neural Network, CNN）**！（可能你都不知道什么是卷积，可以看```03CNN算法\数学基础.MD```。）

但是因为我们让小的**W列表**滑动重复使用，那么**X列表**的每个值也被用了多次，这效率更低了（可以思考一下，多次使用但对要解决的小问题（总问题分的部分）没用的数据，对结果真的没影响吗？）。

而且，我们说要减短**W列表**，那多短呢？太长用的数据还是多，太短可能损失信息（这是**感受野**）。

众多问题告诉我们，要再想想办法。比如用**W列表**对应**X列表**时可以隔几个（提前预设）计算，像```[w1, w2, w3, w4]```，对应```[x1, x2, x3, x4, ...]```，可以视为```[w1, ,w2, ,w3, ,w4]（，，中是空）```与**X列表**8个值对应```（w1*x1+w2*x3+w3*x5+w4*x7）```，这样就扩大了**感受野**。（空洞CNN）

但是，我们固定预设空格，那空格的数据万一对输出数据点很重要怎么办？我们想到可以让“人工智能”来找对输出数据点很重要的点再卷积啊，这便是**可变形卷积**（具体如何找对输出数据点很重要的点再卷积，后续**CNN**会讲到）。

到现在不得不讲讲**W列表**的“妙用”了，思考一下我们当时为什么要**多层**呢？如果你记着是**解决异或问题**，说明你看的很认真，可你想没想过，是怎么解决的？是**线性叠加**，本质上是把一个问题拆成多个问题，然后求解。而**W列表**的值再特定的情况下是可以把数据的特征（**通道**）“算出”，比如我们想找边缘，**W列表**的值可以是```[-1, -1, -1, 0, 0, 0, 1, 1, 1]```，这样就可以把边缘“算出来”，而且这个**W列表**可以重复使用（卷积），这就大大提高了效率（具体后续**CNN**会讲到）。

但是实际的问题可不是一个个简单的**通道**就能解决问题，比如识别**9**,那要先识别**圈**，**线**，再识别别的。那我们需要先提取出基本的空间特征(**DC**)，再进行组合（**PC**）。这就是**深度可分离CNN**的思想。为了减少成本，我们事先把通道数分成几份，并行运算再组合，这便是**分组CNN**的思想。

现在解决一个可能是困惑你已久的问题，我们怎么找的**W列表**能干出那么神奇的效果呢？答案之前有说过，“人工智能”，我们是用数据训练得到的**W列表**。那你会问训练数据得到的**W列表**，别人用的时候的数据。。。还适合吗？答案是  不适合，所以我们可以在卷积前先针对输入数据找到适合的**W列表**，再运算，这就是**动态CNN**的思想。

之前我们一直是把**W列表**改变，那**X列表**呢？我们发现，**CNN**每一层输入都要用到**全部上一层的输出数据**。而我们造多层是为了解决分开的小问题，小问题一定会用到**全部上一层的输出数据**吗？试想一下，我给你一个水果的所有数据问你是什么水果。而你的好领导怕你太累，就让你看这个水果什么形状，让其他人看颜色，气味。你想抱着看这水果全部数据吗？那这领导的好意似乎 0 效果呢。

我们可以让一个“CNN”先快速扫描数据，再对关键区深度计算特征。这是**注意力CNN**，它是为了更准确实现目标，而之前的优化是为了让每个数据输出更准确。

然而它并不是真正“减少”**X列表**，要想真正“减少”**X列表**，那需要把它转为稀疏表，把无用数据的权重消掉，不在滑动，而是查找要算的，进行卷积（这就是**稀疏CNN**）。而事实上，你学了卷积就会明白，3个数的列表与3个数的列表，卷积是5个数字，我们用的时候取中间（二维的图像数据中，是去掉四周的“边”）。你要是稀疏表查找要算的，那多出的输出可不在“边”，再每一个要算的小块的四周，这时我们要去掉所有的无用输出（**子流形CNN**）。

当我们解决了**如何高效提取空间特征**（比如图像里的苹果形状、颜色），我们会发现，有时候数据并提供不全。比如我只需要给你看半张飞机的照片，你也能知道他是一个飞机。这是因为你有**飞机**的概念，你通过联想，用不全的数据得到了完整的信息。应用中，预先设计记忆库，在输入数据中出现就去记忆库寻找，这是**联想式RNN**（注意：**联想式RNN**的发展可早于各种变式CNN，1982年就有）。

之后人们发现现实中还有另一类数据，它们像 “一句话”，“一段语音”，“一帧帧视频”，**顺序**至关重要。比如你看到 “他昨天买了面包，今天把____吃了”，填空要填 “面包”，前提是记得前面提到的 “面包”；要是把句子改成 “他昨天买了面包，今天把____修了”，你会觉得不通顺，因为 “修” 和前面的 “面包” **逻辑**不连贯（联想式RNN也是一种**逻辑顺序**）。而一帧帧视频的顺序不用说了，没顺序一张张图是表达不了原意义，这是**时间**不连贯。

但之前讲的神经网络，处理数据时更像 “一次性把所有信息摊开看”：**FC**不管输入顺序（比如把 “面包 - 吃” 和 “吃 - 面包” 当成一样的输入），**CNN** 关注空间局部关联（比如图像里 “苹果的红色和圆形挨在一起”），却都没考虑 **时间上的先后依赖**。这时候，我们需要一种能 **记住过去** 的模型。

先来想个简单的办法：既然要 “记住过去”，那能不能在模型里加个 “小本子”，把之前处理过的信息记下来，再用到当前计算里？

比如处理句子 “猫追老鼠”：

看到第一个词 “猫” 时，我们用之前熟悉的 “W 列表（权重）” 算一遍，得到一个 “当前状态”（比如记为 h₁，代表 “现在知道有个主体是猫”），同时把 h₁写进 “小本子”；

看到第二个词 “追” 时，除了用新的 W 列表处理 “追”（记为 x₂），还要把 “小本子” 里的 h₁（猫的信息）也加进来一起算，得到新状态 h₂（现在知道 “猫在做追的动作”），再更新 “小本子” 里的内容为 h₂；

看到第三个词 “老鼠” 时，同样用 W 列表处理 “老鼠”（x₃），再结合 “小本子” 里的 h₂（猫追的动作），算出 h₃（最终知道 “猫追老鼠” 的完整逻辑）。

用公式表示，这个过程就是：```hₜ = 激活函数（Wₓ*xₜ + Wₕ*hₜ₋₁ + b）```

这里的 xₜ是 “当前输入”（比如 “追”“老鼠”），hₜ₋₁是 “小本子里的过去状态”（比如 h₁、h₂），Wₕ就是专门用来 “读取过去记忆” 的权重 —— 和 CNN 里 **滑动的 W 列表（卷积核）** 负责**空间关联**不同，RNN 里的 Wₕ负责 **时间关联**。

细心的你会发现，这个 “小本子” 的机制，其实和人类 “边看边记” 的习惯很像：看小说时，你会记住前面的人物关系，才能看懂后面的剧情冲突；听语音时，你会记住前一个音节，才能拼出完整的单词。而这种用 “循环”（把前一时刻的状态 hₜ₋₁再传回来）实现了 “记忆能力” 便是 **RNN** 的核心。

我要强调的是：联想式 RNN 的**记忆库**像一本**常识字典**，比如提前存好‘飞机的完整特征’，当输入‘半张飞机照片’时，直接去字典里查‘飞机’的信息；而普通 RNN 的**小本子**是记**前面输入的内容**（比如句子前半段），两者一个靠**预设常识**，一个靠**实时记忆**。

但和感知机、CNN 一样，早期的 RNN 也有致命缺陷 ——“记不住太久远的事”。就像你看一本几百页的小说，看到最后可能忘了第一章的次要角色；RNN 处理长序列（比如一段 100 个词的句子）时，前面的状态 h₁、h₂传到后面，会像 “传话游戏” 一样，信息越来越弱，最后几乎消失（这在数学上叫 “梯度消失”，就像一杯糖水反复加水，甜味越来越淡）。

比如处理句子 “小明上周去超市买了牛奶，昨天他又去买了果汁，今天早上他喝了____”，RNN 可能记不住 “牛奶” 和 “果汁” 这两个选项，更别说判断 “喝” 对应哪个了。

为了解决 “记不住远期信息” 的问题，科学家们给 RNN 的 “小本子” 加了 “三道闸门”，让它能自主决定 “该记什么、该忘什么、该用什么”—— 这就是**长短期记忆网络（Long Short-Term Memory, LSTM）**。

你可以把 LSTM 的 “记忆单元” 想象成一个 “快递箱”：

遗忘门：像快递员检查箱子，把过期、没用的东西扔掉（比如句子里 “上周去超市” 的细节，对 “今天喝什么” 不重要，就忘掉）；
输入门：把新的重要信息放进箱子（比如 “昨天买了果汁”，和 “喝” 直接相关，就记下来）；
输出门：需要用时，只把箱子里有用的信息拿出来（比如填空时，只提取 “果汁” 的信息，而不是 “超市” 的信息）。

有了这三道门，LSTM 能像 “整理错题本” 一样，选择性保留关键记忆，丢掉无关信息 —— 比如处理长文章时，它能记住主角的名字和主线剧情，忽略无关的环境描写，从而解决了普通 RNN “记不住远期信息” 的问题。

后来，科学家们又在 LSTM 的基础上简化结构，提出了**门控循环单元（Gated Recurrent Unit, GRU）**—— 把 “遗忘门” 和 “输入门” 合并成 “更新门”，像 “一键整理错题本”，既保留了 LSTM 的核心记忆能力，又减少了计算量，在语音识别、文本翻译等场景中更常用。

和 CNN 专注 “空间特征” 不同，RNN（及 LSTM、GRU）专注 “时间序列特征”—— 它们不是替代关系，而是互补：比如处理视频时，CNN 负责提取每一帧图像的空间特征（比如人物的动作、背景的场景），RNN 负责把多帧的特征按时间顺序串起来（比如 “人物先抬手，再弯腰” 的动作逻辑），两者结合就能实现更复杂的智能任务（比如视频内容理解）。

当然，RNN 家族还有更多细分模型（比如双向 RNN、深层 RNN），具体如何设计门控机制、如何处理更长的序列，我们会在后续《RNN 算法详解》章节中展开 —— 就像之前探索 CNN 的变体一样，每一种 RNN 改进，都是为了让模型更精准地 “理解顺序背后的逻辑”。
比如**双向 RNN**就像读句子时既看前面又看后面，比如处理‘____很美味，小明吃了蛋糕’，既要记后面的‘蛋糕’，才能填前面的‘蛋糕’；**深层 RNN**则是‘多层 RNN 叠起来’，像‘先记句子里的词，再记词组成的短语，最后记短语组成的句子’，能捕捉更复杂的序列逻辑。

对于其他的神经网络模型，我不再一一引出，但都在本项目中。（本项目长期更新）。

> 注意！！！，这只是让读者大致认知神经网络体系，深度学习需要学习后续内容。